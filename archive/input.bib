
@article{NgRussell2000,
  author = {Ng, Andrew Y. and Russell, Stuart J.},
  title = {Algorithms for Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2000}
}

@article{Ratliff2006,
  author = {Ratliff, Nathan D. and Bagnell, J. Andrew and Zinkevich, Martin A.},
  title = {Maximum Margin Planning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2006}
}

@article{Abbeel2004,
  author = {Abbeel, Pieter and Ng, Andrew Y.},
  title = {Apprenticeship Learning via Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2004}
}

@article{Ziebart2008,
  author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
  title = {Maximum Entropy Inverse Reinforcement Learning},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2008}
}

@article{Ermon2015,
  author = {Ermon, Stefano and Xue, Yexiang and Toth, Russell and Dilkina, Bistra and Bernstein, Richard and Damoulas, Theodoros and Clark, Patrick and DeGloria, Steve and Mude, Andrew and Barrett, Christopher and Gomes, Carla P.},
  title = {Learning Large-Scale Dynamic Discrete Choice Models of Spatio-Temporal Preferences with Application to Migratory Pastoralism in East Africa},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2015}
}

@article{Wulfmeier2015,
  author = {Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  title = {Maximum Entropy Deep Inverse Reinforcement Learning},
  journal = {arXiv preprint arXiv:1507.04888},
  year = {2015}
}

@article{Ho2016,
  author = {Ho, Jonathan and Ermon, Stefano},
  title = {Generative Adversarial Imitation Learning},
  journal = {Advances in Neural Information Processing Systems},
  year = {2016}
}

@article{Fu2018,
  author = {Fu, Justin and Luo, Katie and Levine, Sergey},
  title = {Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Kostrikov2018,
  author = {Kostrikov, Ilya and Agrawal, Kumar Krishna and Dwibedi, Debidatta and Levine, Sergey and Tompson, Jonathan},
  title = {Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Kim2021,
  author = {Kim, Minyoung and Kim, Joelle and Lakshminarayanan, Aravind S. and Boutilier, Craig and Schuurmans, Dale},
  title = {Reward Identifiability in Inverse Reinforcement Learning},
  journal = {Advances in Neural Information Processing Systems},
  year = {2021}
}

@article{Sharma2018,
  author = {Sharma, Mohit and Sharma, Arjun and Rhinehart, Nicholas and Kitani, Kris M.},
  title = {Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Rust1987,
  author = {Rust, John},
  title = {Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher},
  journal = {Econometrica},
  volume = {55},
  number = {5},
  pages = {999--1033},
  year = {1987}
}

@article{Zeng2022,
  author = {Zeng, Jiawei and Gu, Bin and Huang, Heng},
  title = {A Fully Single Loop Algorithm for Bilevel Optimization without Hessian Inverse},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {7},
  pages = {7426--7434},
  year = {2022}
}

@article{Boularias2011,
  author = {Boularias, Abdeslam and Kober, Jens and Peters, Jan},
  title = {Relative Entropy Inverse Reinforcement Learning},
  journal = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  year = {2011}
}

@article{Bogota2015,
  author = {Bogota, Nicolás and Huang, Xiaocheng and Jebara, Tony},
  title = {Prediction of Refugee Migration Patterns Using Maximum Entropy Inverse Reinforcement Learning},
  journal = {NIPS Workshop on Machine Learning for Social Good},
  year = {2015}
}

@article{Bronner2023,
  author = {Bronner, Yoav and Fishman, Amir and Ritov, Ya'acov and Shimshoni, Ilan},
  title = {Detecting Anomalous Ride-Hailing Driver Routes using Inverse Reinforcement Learning},
  journal = {Transportation Research Part C: Emerging Technologies},
  volume = {146},
  pages = {103982},
  year = {2023}
}

@article{Mai2015,
  author = {Mai, Tien and Fosgerau, Mogens and Frejinger, Emma},
  title = {A Nested Recursive Logit Model for Route Choice Analysis},
  journal = {Transportation Research Part B: Methodological},
  volume = {75},
  pages = {100--112},
  year = {2015}
}

@article{Yancey2022,
  author = {Yancey, Will and Bai, Haotian and Hanna, Rema},
  title = {Inverse Reinforcement Learning for Labor Market Dynamics},
  journal = {Working Paper},
  year = {2022}
}

@article{Chan2019,
  author = {Chan, David C. and Gentzkow, Matthew and Yu, Chuan},
  title = {Selection with Variation in Diagnostic Skill: Evidence from Radiologists},
  journal = {The Quarterly Journal of Economics},
  volume = {137},
  number = {2},
  pages = {729--783},
  year = {2019}
}

@article{Ramachandran2007,
  author = {Ramachandran, Deepak and Amir, Eyal},
  title = {Bayesian Inverse Reinforcement Learning},
  journal = {Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
  year = {2007}
}

@article{Finn2016,
  author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  title = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2016}
}

@article{Baram2017,
  author = {Baram, Nir and Anschel, Oron and Caspi, Itai and Mannor, Shie},
  title = {End-to-End Differentiable Adversarial Imitation Learning},
  journal = {Proceedings of Machine Learning Research},
  volume = {70},
  year = {2017}
}

@article{Kang2025,
  author = {Kang, Enoch Hyunwook},
  title = {Gradients can train reward models: An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model},
  journal = {arXiv preprint arXiv:2502.14131},
  year = {2025}
}


@article{NgRussell2000,
  author = {Ng, Andrew Y. and Russell, Stuart J.},
  title = {Algorithms for Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2000}
}

@article{Ratliff2006,
  author = {Ratliff, Nathan D. and Bagnell, J. Andrew and Zinkevich, Martin A.},
  title = {Maximum Margin Planning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2006}
}

@article{Abbeel2004,
  author = {Abbeel, Pieter and Ng, Andrew Y.},
  title = {Apprenticeship Learning via Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2004}
}

@article{Ziebart2008,
  author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
  title = {Maximum Entropy Inverse Reinforcement Learning},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2008}
}

@article{Ermon2015,
  author = {Ermon, Stefano and Xue, Yexiang and Toth, Russell and Dilkina, Bistra and Bernstein, Richard and Damoulas, Theodoros and Clark, Patrick and DeGloria, Steve and Mude, Andrew and Barrett, Christopher and Gomes, Carla P.},
  title = {Learning Large-Scale Dynamic Discrete Choice Models of Spatio-Temporal Preferences with Application to Migratory Pastoralism in East Africa},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2015}
}

@article{Wulfmeier2015,
  author = {Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  title = {Maximum Entropy Deep Inverse Reinforcement Learning},
  journal = {arXiv preprint arXiv:1507.04888},
  year = {2015}
}

@article{Ho2016,
  author = {Ho, Jonathan and Ermon, Stefano},
  title = {Generative Adversarial Imitation Learning},
  journal = {Advances in Neural Information Processing Systems},
  year = {2016}
}

@article{Fu2018,
  author = {Fu, Justin and Luo, Katie and Levine, Sergey},
  title = {Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Kostrikov2018,
  author = {Kostrikov, Ilya and Agrawal, Kumar Krishna and Dwibedi, Debidatta and Levine, Sergey and Tompson, Jonathan},
  title = {Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Kim2021,
  author = {Kim, Minyoung and Kim, Joelle and Lakshminarayanan, Aravind S. and Boutilier, Craig and Schuurmans, Dale},
  title = {Reward Identifiability in Inverse Reinforcement Learning},
  journal = {Advances in Neural Information Processing Systems},
  year = {2021}
}

@article{Sharma2018,
  author = {Sharma, Mohit and Sharma, Arjun and Rhinehart, Nicholas and Kitani, Kris M.},
  title = {Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Rust1987,
  author = {Rust, John},
  title = {Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher},
  journal = {Econometrica},
  volume = {55},
  number = {5},
  pages = {999--1033},
  year = {1987}
}

@article{Zeng2022,
  author = {Zeng, Jiawei and Gu, Bin and Huang, Heng},
  title = {A Fully Single Loop Algorithm for Bilevel Optimization without Hessian Inverse},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {7},
  pages = {7426--7434},
  year = {2022}
}

@article{Boularias2011,
  author = {Boularias, Abdeslam and Kober, Jens and Peters, Jan},
  title = {Relative Entropy Inverse Reinforcement Learning},
  journal = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  year = {2011}
}

@article{Bogota2015,
  author = {Bogota, Nicolás and Huang, Xiaocheng and Jebara, Tony},
  title = {Prediction of Refugee Migration Patterns Using Maximum Entropy Inverse Reinforcement Learning},
  journal = {NIPS Workshop on Machine Learning for Social Good},
  year = {2015}
}

@article{Bronner2023,
  author = {Bronner, Yoav and Fishman, Amir and Ritov, Ya'acov and Shimshoni, Ilan},
  title = {Detecting Anomalous Ride-Hailing Driver Routes using Inverse Reinforcement Learning},
  journal = {Transportation Research Part C: Emerging Technologies},
  volume = {146},
  pages = {103982},
  year = {2023}
}

@article{Mai2015,
  author = {Mai, Tien and Fosgerau, Mogens and Frejinger, Emma},
  title = {A Nested Recursive Logit Model for Route Choice Analysis},
  journal = {Transportation Research Part B: Methodological},
  volume = {75},
  pages = {100--112},
  year = {2015}
}

@article{Yancey2022,
  author = {Yancey, Will and Bai, Haotian and Hanna, Rema},
  title = {Inverse Reinforcement Learning for Labor Market Dynamics},
  journal = {Working Paper},
  year = {2022}
}

@article{Chan2019,
  author = {Chan, David C. and Gentzkow, Matthew and Yu, Chuan},
  title = {Selection with Variation in Diagnostic Skill: Evidence from Radiologists},
  journal = {The Quarterly Journal of Economics},
  volume = {137},
  number = {2},
  pages = {729--783},
  year = {2019}
}

@article{Ramachandran2007,
  author = {Ramachandran, Deepak and Amir, Eyal},
  title = {Bayesian Inverse Reinforcement Learning},
  journal = {Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
  year = {2007}
}

@article{Finn2016,
  author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  title = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2016}
}

@article{Igami2020,
  author = {Igami, Mitsuru},
  title = {Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo},
  journal = {The Review of Economic Studies},
  year = {2020}
}

@article{Hollenbeck2019,
  author = {Hollenbeck, Brett},
  title = {Horizontal Mergers and Innovation in Concentrated Industries},
  journal = {Quantitative Marketing and Economics},
  year = {2019}
}

@article{HuYang2025,
  author = {Hu, Yingyao and Yang, Zhangyi},
  title = {Structural Estimation with Policy Gradient Methods},
  journal = {Working Paper},
  year = {2025}
}

@article{AtashbarShi2023,
  author = {Atashbar, Tohid and Shi, Shuping},
  title = {Solving Macroeconomic Models with Deep Reinforcement Learning},
  journal = {Journal of Economic Dynamics and Control},
  year = {2023}
}

@article{HinterlangTaenzer2024,
  author = {Hinterlang, Natascha and Taenzer, Tobias},
  title = {Optimal Monetary Policy using Reinforcement Learning},
  journal = {Journal of Monetary Economics},
  year = {2024}
}

@article{Igami2020b,
  author = {Igami, Mitsuru},
  title = {Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo},
  journal = {The Review of Economic Studies},
  year = {2020}
}

@article{ZengEtAl2024,
  author = {Zeng, Jiawei and Gu, Bin and Huang, Heng and Kang, Enoch Hyunwook},
  title = {Single-Loop Algorithms for Inverse Reinforcement Learning and Dynamic Discrete Choice Estimation},
  journal = {Working Paper},
  year = {2024}
}


@article{NgRussell2000,
  author = {Ng, Andrew Y. and Russell, Stuart J.},
  title = {Algorithms for Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2000}
}

@article{Ratliff2006,
  author = {Ratliff, Nathan D. and Bagnell, J. Andrew and Zinkevich, Martin A.},
  title = {Maximum Margin Planning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2006}
}

@article{Abbeel2004,
  author = {Abbeel, Pieter and Ng, Andrew Y.},
  title = {Apprenticeship Learning via Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2004}
}

@article{Ziebart2008,
  author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
  title = {Maximum Entropy Inverse Reinforcement Learning},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2008}
}

@article{Ermon2015,
  author = {Ermon, Stefano and Xue, Yexiang and Toth, Russell and Dilkina, Bistra and Bernstein, Richard and Damoulas, Theodoros and Clark, Patrick and DeGloria, Steve and Mude, Andrew and Barrett, Christopher and Gomes, Carla P.},
  title = {Learning Large-Scale Dynamic Discrete Choice Models of Spatio-Temporal Preferences with Application to Migratory Pastoralism in East Africa},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2015}
}

@article{Wulfmeier2015,
  author = {Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  title = {Maximum Entropy Deep Inverse Reinforcement Learning},
  journal = {arXiv preprint arXiv:1507.04888},
  year = {2015}
}

@article{Ho2016,
  author = {Ho, Jonathan and Ermon, Stefano},
  title = {Generative Adversarial Imitation Learning},
  journal = {Advances in Neural Information Processing Systems},
  year = {2016}
}

@article{Fu2018,
  author = {Fu, Justin and Luo, Katie and Levine, Sergey},
  title = {Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Kostrikov2018,
  author = {Kostrikov, Ilya and Agrawal, Kumar Krishna and Dwibedi, Debidatta and Levine, Sergey and Tompson, Jonathan},
  title = {Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Kim2021,
  author = {Kim, Minyoung and Kim, Joelle and Lakshminarayanan, Aravind S. and Boutilier, Craig and Schuurmans, Dale},
  title = {Reward Identifiability in Inverse Reinforcement Learning},
  journal = {Advances in Neural Information Processing Systems},
  year = {2021}
}

@article{Sharma2018,
  author = {Sharma, Mohit and Sharma, Arjun and Rhinehart, Nicholas and Kitani, Kris M.},
  title = {Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Rust1987,
  author = {Rust, John},
  title = {Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher},
  journal = {Econometrica},
  volume = {55},
  number = {5},
  pages = {999--1033},
  year = {1987}
}

@article{Zeng2022,
  author = {Zeng, Jiawei and Gu, Bin and Huang, Heng},
  title = {A Fully Single Loop Algorithm for Bilevel Optimization without Hessian Inverse},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {7},
  pages = {7426--7434},
  year = {2022}
}

@article{Boularias2011,
  author = {Boularias, Abdeslam and Kober, Jens and Peters, Jan},
  title = {Relative Entropy Inverse Reinforcement Learning},
  journal = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  year = {2011}
}

@article{Bogota2015,
  author = {Bogota, Nicolás and Huang, Xiaocheng and Jebara, Tony},
  title = {Prediction of Refugee Migration Patterns Using Maximum Entropy Inverse Reinforcement Learning},
  journal = {NIPS Workshop on Machine Learning for Social Good},
  year = {2015}
}

@article{Bronner2023,
  author = {Bronner, Yoav and Fishman, Amir and Ritov, Ya'acov and Shimshoni, Ilan},
  title = {Detecting Anomalous Ride-Hailing Driver Routes using Inverse Reinforcement Learning},
  journal = {Transportation Research Part C: Emerging Technologies},
  volume = {146},
  pages = {103982},
  year = {2023}
}

@article{Mai2015,
  author = {Mai, Tien and Fosgerau, Mogens and Frejinger, Emma},
  title = {A Nested Recursive Logit Model for Route Choice Analysis},
  journal = {Transportation Research Part B: Methodological},
  volume = {75},
  pages = {100--112},
  year = {2015}
}

@article{Yancey2022,
  author = {Yancey, Will and Bai, Haotian and Hanna, Rema},
  title = {Inverse Reinforcement Learning for Labor Market Dynamics},
  journal = {Working Paper},
  year = {2022}
}

@article{Chan2019,
  author = {Chan, David C. and Gentzkow, Matthew and Yu, Chuan},
  title = {Selection with Variation in Diagnostic Skill: Evidence from Radiologists},
  journal = {The Quarterly Journal of Economics},
  volume = {137},
  number = {2},
  pages = {729--783},
  year = {2019}
}

@article{Ramachandran2007,
  author = {Ramachandran, Deepak and Amir, Eyal},
  title = {Bayesian Inverse Reinforcement Learning},
  journal = {Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
  year = {2007}
}

@article{Finn2016,
  author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  title = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2016}
}

@article{Igami2020,
  author = {Igami, Mitsuru},
  title = {Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo},
  journal = {The Review of Economic Studies},
  year = {2020}
}

@article{Hollenbeck2019,
  author = {Hollenbeck, Brett},
  title = {Horizontal Mergers and Innovation in Concentrated Industries},
  journal = {Quantitative Marketing and Economics},
  year = {2019}
}

@article{HuYang2025,
  author = {Hu, Yingyao and Yang, Zhangyi},
  title = {Structural Estimation with Policy Gradient Methods},
  journal = {Working Paper},
  year = {2025}
}

@article{AtashbarShi2023,
  author = {Atashbar, Tohid and Shi, Shuping},
  title = {Solving Macroeconomic Models with Deep Reinforcement Learning},
  journal = {Journal of Economic Dynamics and Control},
  year = {2023}
}

@article{HinterlangTaenzer2024,
  author = {Hinterlang, Natascha and Taenzer, Tobias},
  title = {Optimal Monetary Policy using Reinforcement Learning},
  journal = {Journal of Monetary Economics},
  year = {2024}
}

@article{Igami2020b,
  author = {Igami, Mitsuru},
  title = {Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo},
  journal = {The Review of Economic Studies},
  year = {2020}
}

@article{ZengEtAl2024,
  author = {Zeng, Jiawei and Gu, Bin and Huang, Heng and Kang, Enoch Hyunwook},
  title = {Single-Loop Algorithms for Inverse Reinforcement Learning and Dynamic Discrete Choice Estimation},
  journal = {Working Paper},
  year = {2024}
}

@article{BorgersSarin1997,
  author = {Börgers, Tilman and Sarin, Rajiv},
  title = {Learning through reinforcement and replicator dynamics},
  year = {1997}
}

@article{Cross1973,
  author = {Cross, John G.},
  title = {A stochastic learning model of economic behavior},
  year = {1973}
}

@article{TuylsNowe2005,
  author = {Tuyls, Karl and Nowé, Ann},
  title = {Evolutionary game theory and multi-agent reinforcement learning},
  year = {2005}
}

@article{Tuyls2006,
  author = {Tuyls, Karl and others},
  title = {An evolutionary game theoretic perspective on learning in multi-agent systems},
  year = {2006}
}

@article{KaisersTuyls2010,
  author = {Kaisers, Michael and Tuyls, Karl},
  title = {Frequency adjusted multi-agent Q-learning},
  year = {2010}
}

@article{Robinson1951,
  author = {Robinson, Julia},
  title = {An iterative method of solving a game},
  year = {1951}
}

@article{MondererShapley1996,
  author = {Monderer, Dov and Shapley, Lloyd S.},
  title = {Potential games},
  year = {1996}
}

@article{Shapley1964,
  author = {Shapley, Lloyd S.},
  title = {Some topics in two-person games},
  year = {1964}
}

@article{Littman1994,
  author = {Littman, Michael L.},
  title = {Markov games as a framework for multi-agent reinforcement learning},
  year = {1994}
}

@article{HuWellman2003,
  author = {Hu, Junling and Wellman, Michael P.},
  title = {Nash Q-learning for general-sum stochastic games},
  year = {2003}
}

@article{ConitzerSandholm2007,
  author = {Conitzer, Vincent and Sandholm, Tuomas},
  title = {AWESOME: A general multiagent learning algorithm},
  year = {2007}
}

@article{HartMasColell2000,
  author = {Hart, Sergiu and Mas-Colell, Andreu},
  title = {A simple adaptive procedure leading to correlated equilibrium},
  year = {2000}
}

@article{Brown1951,
  author = {Brown, George W.},
  title = {Iterative solution of games by fictitious play},
  year = {1951}
}

@article{HeinrichSilver2016,
  author = {Heinrich, Johannes and Silver, David},
  title = {Neural fictitious self-play},
  year = {2016}
}

@article{Lanctot2017,
  author = {Lanctot, Marc and others},
  title = {A unified game-theoretic approach to multiagent reinforcement learning},
  year = {2017}
}

@article{Zinkevich2008,
  author = {Zinkevich, Martin and others},
  title = {Regret minimization in games with incomplete information},
  year = {2008}
}

@article{Mazumdar2019,
  author = {Mazumdar, Eric and others},
  title = {On gradient-based learning in continuous games},
  year = {2019}
}

@article{LeslieCollins2005,
  author = {Leslie, David S. and Collins, E. J.},
  title = {Individual Q-learning in normal form games},
  year = {2005}
}

@article{Klos2010,
  author = {Klos, Tomas},
  title = {Evolutionary dynamics of regret minimization},
  year = {2010}
}

@article{ShGrePow2007,
  author = {Shoham, Yoav and Powers, Rob and Grenager, Trond},
  title = {If multi-agent learning is the answer, what is the question?},
  year = {2007}
}

@article{Bloembergen2015,
  author = {Bloembergen, Daan and others},
  title = {Evolutionary dynamics of multi-agent learning},
  year = {2015}
}

@article{BlumMansour2007,
  author = {Blum, Avrim and Mansour, Yishay},
  title = {Learning, regret minimization, and equilibria},
  year = {2007}
}


@article{NgRussell2000,
  author = {Ng, Andrew Y. and Russell, Stuart J.},
  title = {Algorithms for Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2000}
}

@article{Abbeel2004,
  author = {Abbeel, Pieter and Ng, Andrew Y.},
  title = {Apprenticeship Learning via Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2004}
}

@book{SuttonBarto1998,
  author = {Sutton, Richard S. and Barto, Andrew G.},
  title = {Reinforcement Learning: An Introduction},
  publisher = {MIT Press},
  year = {1998}
}

@article{Igami2020b,
  author = {Igami, Mitsuru},
  title = {Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo},
  journal = {The Review of Economic Studies},
  year = {2020}
}


@article{Shannon1950,
  author = {Shannon, Claude E.},
  title = {Programming a Computer for Playing Chess},
  journal = {Philosophical Magazine},
  volume = {41},
  number = {314},
  year = {1950}
}

@phdthesis{Minsky1954,
  author = {Minsky, Marvin},
  title = {Neural Nets and the Brain Model Problem},
  school = {Princeton University},
  year = {1954}
}

@article{Samuel1959,
  author = {Samuel, Arthur L.},
  title = {Some Studies in Machine Learning Using the Game of Checkers},
  journal = {IBM Journal of Research and Development},
  volume = {3},
  number = {3},
  pages = {210--229},
  year = {1959}
}

@book{Bellman1957,
  author = {Bellman, Richard},
  title = {Dynamic Programming},
  publisher = {Princeton University Press},
  year = {1957}
}

@article{NgRussell2000,
  author = {Ng, Andrew Y. and Russell, Stuart J.},
  title = {Algorithms for Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2000}
}

@article{Ratliff2006,
  author = {Ratliff, Nathan D. and Bagnell, J. Andrew and Zinkevich, Martin A.},
  title = {Maximum Margin Planning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2006}
}

@article{Abbeel2004,
  author = {Abbeel, Pieter and Ng, Andrew Y.},
  title = {Apprenticeship Learning via Inverse Reinforcement Learning},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2004}
}

@article{Ziebart2008,
  author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
  title = {Maximum Entropy Inverse Reinforcement Learning},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2008}
}

@article{Ermon2015,
  author = {Ermon, Stefano and Xue, Yexiang and Toth, Russell and Dilkina, Bistra and Bernstein, Richard and Damoulas, Theodoros and Clark, Patrick and DeGloria, Steve and Mude, Andrew and Barrett, Christopher and Gomes, Carla P.},
  title = {Learning Large-Scale Dynamic Discrete Choice Models of Spatio-Temporal Preferences with Application to Migratory Pastoralism in East Africa},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2015}
}

@article{Wulfmeier2015,
  author = {Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  title = {Maximum Entropy Deep Inverse Reinforcement Learning},
  journal = {arXiv preprint arXiv:1507.04888},
  year = {2015}
}

@article{Ho2016,
  author = {Ho, Jonathan and Ermon, Stefano},
  title = {Generative Adversarial Imitation Learning},
  journal = {Advances in Neural Information Processing Systems},
  year = {2016}
}

@article{Fu2018,
  author = {Fu, Justin and Luo, Katie and Levine, Sergey},
  title = {Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Kostrikov2018,
  author = {Kostrikov, Ilya and Agrawal, Kumar Krishna and Dwibedi, Debidatta and Levine, Sergey and Tompson, Jonathan},
  title = {Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Kim2021,
  author = {Kim, Minyoung and Kim, Joelle and Lakshminarayanan, Aravind S. and Boutilier, Craig and Schuurmans, Dale},
  title = {Reward Identifiability in Inverse Reinforcement Learning},
  journal = {Advances in Neural Information Processing Systems},
  year = {2021}
}

@article{Sharma2018,
  author = {Sharma, Mohit and Sharma, Arjun and Rhinehart, Nicholas and Kitani, Kris M.},
  title = {Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2018}
}

@article{Rust1987,
  author = {Rust, John},
  title = {Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher},
  journal = {Econometrica},
  volume = {55},
  number = {5},
  pages = {999--1033},
  year = {1987}
}

@article{Zeng2022,
  author = {Zeng, Jiawei and Gu, Bin and Huang, Heng},
  title = {A Fully Single Loop Algorithm for Bilevel Optimization without Hessian Inverse},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {7},
  pages = {7426--7434},
  year = {2022}
}

@article{Boularias2011,
  author = {Boularias, Abdeslam and Kober, Jens and Peters, Jan},
  title = {Relative Entropy Inverse Reinforcement Learning},
  journal = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  year = {2011}
}

@article{Bogota2015,
  author = {Bogota, Nicolás and Huang, Xiaocheng and Jebara, Tony},
  title = {Prediction of Refugee Migration Patterns Using Maximum Entropy Inverse Reinforcement Learning},
  journal = {NIPS Workshop on Machine Learning for Social Good},
  year = {2015}
}

@article{Bronner2023,
  author = {Bronner, Yoav and Fishman, Amir and Ritov, Ya'acov and Shimshoni, Ilan},
  title = {Detecting Anomalous Ride-Hailing Driver Routes using Inverse Reinforcement Learning},
  journal = {Transportation Research Part C: Emerging Technologies},
  volume = {146},
  pages = {103982},
  year = {2023}
}

@article{Mai2015,
  author = {Mai, Tien and Fosgerau, Mogens and Frejinger, Emma},
  title = {A Nested Recursive Logit Model for Route Choice Analysis},
  journal = {Transportation Research Part B: Methodological},
  volume = {75},
  pages = {100--112},
  year = {2015}
}

@article{Yancey2022,
  author = {Yancey, Will and Bai, Haotian and Hanna, Rema},
  title = {Inverse Reinforcement Learning for Labor Market Dynamics},
  journal = {Working Paper},
  year = {2022}
}

@article{Chan2019,
  author = {Chan, David C. and Gentzkow, Matthew and Yu, Chuan},
  title = {Selection with Variation in Diagnostic Skill: Evidence from Radiologists},
  journal = {The Quarterly Journal of Economics},
  volume = {137},
  number = {2},
  pages = {729--783},
  year = {2019}
}

@article{Ramachandran2007,
  author = {Ramachandran, Deepak and Amir, Eyal},
  title = {Bayesian Inverse Reinforcement Learning},
  journal = {Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
  year = {2007}
}

@article{Finn2016,
  author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  title = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2016}
}

@article{Igami2020,
  author = {Igami, Mitsuru},
  title = {Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo},
  journal = {The Review of Economic Studies},
  year = {2020}
}

@article{Hollenbeck2019,
  author = {Hollenbeck, Brett},
  title = {Horizontal Mergers and Innovation in Concentrated Industries},
  journal = {Quantitative Marketing and Economics},
  year = {2019}
}

@article{HuYang2025,
  author = {Hu, Yingyao and Yang, Zhangyi},
  title = {Structural Estimation with Policy Gradient Methods},
  journal = {Working Paper},
  year = {2025}
}

@article{AtashbarShi2023,
  author = {Atashbar, Tohid and Shi, Shuping},
  title = {Solving Macroeconomic Models with Deep Reinforcement Learning},
  journal = {Journal of Economic Dynamics and Control},
  year = {2023}
}

@article{HinterlangTaenzer2024,
  author = {Hinterlang, Natascha and Taenzer, Tobias},
  title = {Optimal Monetary Policy using Reinforcement Learning},
  journal = {Journal of Monetary Economics},
  year = {2024}
}

@article{Igami2020b,
  author = {Igami, Mitsuru},
  title = {Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo},
  journal = {The Review of Economic Studies},
  year = {2020}
}

@article{ZengEtAl2024,
  author = {Zeng, Jiawei and Gu, Bin and Huang, Heng and Kang, Enoch Hyunwook},
  title = {Single-Loop Algorithms for Inverse Reinforcement Learning and Dynamic Discrete Choice Estimation},
  journal = {Working Paper},
  year = {2024}
}

@article{Skinner1963,
  author = {Skinner, B. F.},
  title = {Operant Behavior},
  journal = {American Psychologist},
  volume = {18},
  number = {8},
  pages = {503--515},
  year = {1963}
}

@book{Thorndike1913,
  author = {Thorndike, Edward L.},
  title = {Educational Psychology: The Psychology of Learning},
  publisher = {Teachers College, Columbia University},
  year = {1913}
}

@article{Jones1924,
  author = {Jones, Mary Cover},
  title = {The Elimination of Children's Fears},
  journal = {Journal of Experimental Psychology},
  volume = {7},
  number = {5},
  pages = {382--390},
  year = {1924}
}

@article{Dickinson1978,
  author = {Dickinson, Anthony},
  title = {Contemporary Animal Learning Theory},
  journal = {Cambridge University Press},
  year = {1978}
}

@article{Wagner1972,
  author = {Wagner, Allan R. and Rescorla, Robert A.},
  title = {A Theory of Pavlovian Conditioning: Variations in the Effectiveness of Reinforcement and Nonreinforcement},
  journal = {Classical Conditioning II: Current Research and Theory},
  pages = {64--99},
  year = {1972}
}

@article{Shannon1950,
  author = {Shannon, Claude E.},
  title = {Programming a Computer for Playing Chess},
  journal = {Philosophical Magazine},
  volume = {41},
  number = {314},
  year = {1950}
}

@phdthesis{Minsky1954,
  author = {Minsky, Marvin},
  title = {Neural Nets and the Brain Model Problem},
  school = {Princeton University},
  year = {1954}
}

@article{Samuel1959,
  author = {Samuel, Arthur L.},
  title = {Some Studies in Machine Learning Using the Game of Checkers},
  journal = {IBM Journal of Research and Development},
  volume = {3},
  number = {3},
  pages = {210--229},
  year = {1959}
}

@book{Bellman1957,
  author = {Bellman, Richard},
  title = {Dynamic Programming},
  publisher = {Princeton University Press},
  year = {1957}
}

@book{Howard1961,
  author = {Howard, Ronald A.},
  title = {Dynamic Programming and Markov Processes},
  publisher = {MIT Press},
  year = {1961}
}

@book{SuttonBarto1998,
  author = {Sutton, Richard S. and Barto, Andrew G.},
  title = {Reinforcement Learning: An Introduction},
  publisher = {MIT Press},
  year = {1998}
}

@article{Mnih2015,
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  title = {Human-level control through deep reinforcement learning},
  journal = {Nature},
  volume = {518},
  number = {7540},
  pages = {529--533},
  year = {2015}
}

@article{Schulman2015,
  author = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  title = {Trust Region Policy Optimization},
  journal = {Proceedings of the 32nd International Conference on Machine Learning},
  pages = {1889--1897},
  year = {2015}
}

@article{Schulman2017,
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  title = {Proximal Policy Optimization Algorithms},
  journal = {arXiv preprint arXiv:1707.06347},
  year = {2017}
}

@article{Haarnoja2018,
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  journal = {Proceedings of the 35th International Conference on Machine Learning},
  pages = {1861--1870},
  year = {2018}
}

@article{Silver2016,
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  title = {Mastering the game of Go with deep neural networks and tree search},
  journal = {Nature
}

@article{Silver2016,
author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
title = {Mastering the game of Go with deep neural networks and tree search},
journal = {Nature},
volume = {529},
number = {7587},
pages = {484--489},
year = {2016}
}

@article{Silver2017,
author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
title = {Mastering the Game of Go without Human Knowledge},
journal = {Nature},
volume = {550},
number = {7676},
pages = {354--359},
year = {2017}
}

@article{Silver2018,
author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
journal = {Science},
volume = {362},
number = {6419},
pages = {1140--1144},
year = {2018}
}

@article{OpenAIFive2019,
author = {OpenAI and Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dębiak, Przemysław and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Józefowicz, Rafał and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and Pinto, Henrique Pondé de Oliveira and Raiman, Jonathan and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
title = {Dota 2 with Large Scale Deep Reinforcement Learning},
journal = {arXiv preprint arXiv:1912.06680},
year = {2019}
}

@article{Schrittwieser2020,
author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
title = {Mastering Atari, Go, chess and shogi by planning with a learned model},
journal = {Nature},
volume = {588},
number = {7839},
pages = {604--609},
year = {2020}
}

@article{Watkins1992,
author = {Watkins, Christopher J.C.H. and Dayan, Peter},
title = {Q-learning},
journal = {Machine Learning},
volume = {8},
number = {3-4},
pages = {279--292},
year = {1992}
}

@article{Williams1992,
author = {Williams, Ronald J.},
title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
journal = {Machine Learning},
volume = {8},
number = {3-4},
pages = {229--256},
year = {1992}
}

@article{Sutton1999,
author = {Sutton, Richard S. and McAllester, David A. and Singh, Satinder P. and Mansour, Yishay},
title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
journal = {Advances in Neural Information Processing Systems},
volume = {12},
year = {1999}
}

@article{Sutton1999Options,
author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
title = {Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
journal = {Artificial Intelligence},
volume = {112},
number = {1-2},
pages = {181--211},
year = {1999}
}

@article{Dietterich2000,
author = {Dietterich, Thomas G.},
title = {Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition},
journal = {Journal of Artificial Intelligence Research},
volume = {13},
pages = {227--303},
year = {2000}
}

@article{Kakade2001,
author = {Kakade, Sham M.},
title = {A Natural Policy Gradient},
journal = {Advances in Neural Information Processing Systems},
volume = {14},
year = {2001}
}

@article{Brafman2002,
author = {Brafman, Ronen I. and Tennenholtz, Moshe},
title = {R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning},
journal = {Journal of Machine Learning Research},
volume = {3},
pages = {213--231},
year = {2002}
}

@article{Lagoudakis2003,
author = {Lagoudakis, Michail G. and Parr, Ronald},
title = {Least-Squares Policy Iteration},
journal = {Journal of Machine Learning Research},
volume = {4},
pages = {1107--1149},
year = {2003}
}

@article{Riedmiller2005,
author = {Riedmiller, Martin},
title = {Neural Fitted Q Iteration – First Experiences with a Data Efficient Neural Reinforcement Learning Method},
journal = {European Conference on Machine Learning},
pages = {317--328},
year = {2005}
}

@article{Silver2010,
author = {Silver, David and Veness, Joel},
title = {Monte-Carlo Planning in Large POMDPs},
journal = {Advances in Neural Information Processing Systems},
volume = {23},
year = {2010}
}

@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
title = {Human-level control through deep reinforcement learning},
journal = {Nature},
volume = {518},
number = {7540},
pages = {529--533},
year = {2015}
}

@article{Schulman2015,
author = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
title = {Trust Region Policy Optimization},
journal = {Proceedings of the 32nd International Conference on Machine Learning},
pages = {1889--1897},
year = {2015}
}

@article{Schulman2017,
author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
title = {Proximal Policy Optimization Algorithms},
journal = {arXiv preprint arXiv:1707.06347},
year = {2017}
}

@article{Haarnoja2018,
author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
journal = {Proceedings of the 35th International Conference on Machine Learning},
pages = {1861--1870},
year = {2018}
}

@article{Vinyals2019,
author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, Rémi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and Wünsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
title = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
journal = {Nature},
volume = {575},
number = {7782},
pages = {350--354},
year = {2019}
}

@article{Ouyang2022,
author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
title = {Training language models to follow instructions with human feedback},
journal = {arXiv preprint arXiv:2203.02155},
year = {2022}
}

@article{Glaese2022,
author = {Glaese, Amelia and McAleese, Nat and Trębacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Ramaswamy, Maribeth and Toyama, Lena and Babuschkin, Igor and Scholz, Julien and Chung, Mia and Mourad, Abram and Tunison, Sarah and Dyer, Jack and Dudzik, Askell, Amanda and Romera-Paredes, Bernardino and Kohli, Pushmeet and Kavukcuoglu, Koray and Legg, Shane and Irving, Geoffrey},
title = {Improving alignment of dialogue agents via targeted human judgements},
journal = {arXiv preprint arXiv:2209.14375},
year = {2022}
}

@article{Bai2022,
author = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and Chen, Carol and Olsson, Catherine and Lanham, Benjamin and Tian, Carrick and Baljekar, Pranav and Huang, Shauna and Gonzalez, Sheer El and Christiano, Paul and Leike, Jan and Krueger, Ryan},
title = {Constitutional AI: Harmlessness from AI Feedback},
journal = {arXiv preprint arXiv:2212.08073},
year = {2022}
}

@article{DeepSeekR1_2025,
author = {DeepSeek AI Research Team},
title = {DeepSeek R1: A Reasoning-centric Large Language Model},
journal = {arXiv preprint},
year = {2025}
}